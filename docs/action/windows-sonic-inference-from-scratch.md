# Windows SONIC æ¨ç†å®Œæ•´å®ç°è®°å½•

**æ—¥æœŸ**: 2026-02-01  
**ç›®æ ‡**: Windows + NVIDIA GPU (RTX 3060 Ti) ä¸Šå¿«é€Ÿå¯åŠ¨ tinyworlds SONIC æ•°æ®é›†æ¨ç†  
**æœ€ç»ˆçŠ¶æ€**: âœ… æ¨ç†æˆåŠŸï¼ˆè‡ªåŠ¨ + äº¤äº’æ¨¡å¼å‡å¯ç”¨ï¼‰

---

## æ‰§è¡Œè¿‡ç¨‹

### Step 0: ç¡¬ä»¶ç¯å¢ƒè‡ªæ£€
- **æ˜¾å¡**: NVIDIA GeForce RTX 3060 Ti (8GB)
- **é©±åŠ¨ç‰ˆæœ¬**: 560.94 with CUDA 12.6
- **Python ç‰ˆæœ¬**: 3.11.4
- **ç³»ç»Ÿ**: Windows (PowerShell)
- âœ… **éªŒè¯**: `nvidia-smi` æ­£å¸¸ï¼ŒCUDA runtime å¯ç”¨

### Step 1: è™šæ‹Ÿç¯å¢ƒè®¾ç½®
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
python -m pip install -U pip
```
- âœ… è™šæ‹Ÿç¯å¢ƒæ¿€æ´»æˆåŠŸï¼Œpip å‡çº§è‡³ 26.0

### Step 2: PyTorch CUDA å®‰è£…ï¼ˆå…³é”®ï¼‰
```powershell
pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/cu126
```
- PyTorch ç‰ˆæœ¬: **2.8.0+cu126**
- æ€»å¤§å°: ~2.9 GB
- âœ… `torch.cuda.is_available()` = **True**
- âœ… `torch.cuda.get_device_name(0)` = **NVIDIA GeForce RTX 3060 Ti**

### Step 3: ä¾èµ–å®‰è£…ï¼ˆå‰¥ç¦» torchï¼‰
åˆ›å»º `requirements-notorch.txt`ï¼Œç§»é™¤äº† torch/torchvision/torchaudio ä¾èµ–ï¼Œé˜²æ­¢è¢«è¦†ç›–ï¼š
```powershell
(Get-Content requirements.txt) | Where-Object { $_ -notmatch '^(torch|torchvision|torchaudio)\b' } | Set-Content requirements-notorch.txt
pip install -r requirements-notorch.txt
```
**å®‰è£…åŒ…**: wandb, h5py, opencv-python, omegaconf, huggingface_hub ç­‰

- âœ… æ‰€æœ‰ä¾èµ–å®‰è£…æˆåŠŸ

### Step 4: æ•°æ® + æ¨¡å‹ä¸‹è½½

#### 4.1 SONIC æ•°æ®é›†ä¸‹è½½
```powershell
python -c "
import os
from huggingface_hub import hf_hub_download
os.makedirs('data', exist_ok=True)
os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '0'
path = hf_hub_download(
    repo_id='AlmondGod/tinyworlds',
    filename='sonic_frames.h5',
    repo_type='dataset',
    local_dir='data',
    local_dir_use_symlinks=False,
)
print(f'Downloaded: {path}')
"
```
- **æ–‡ä»¶**: `data/sonic_frames.h5`
- **å¤§å°**: 249 MB
- âœ… ä¸‹è½½æˆåŠŸ

#### 4.2 é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½
```powershell
python -c "
import os
from datetime import datetime
from pathlib import Path
from huggingface_hub import hf_hub_download

os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '0'
repo_id = 'AlmondGod/tinyworlds-models'
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
results_dir = Path('results') / f'{timestamp}_sonic'

models = [
    'sonic/sonic_video_tokenizer_step_27500_2025_09_17_06_20_26.pth',
    'sonic/sonic_latent_actions_step_2500_2025_09_17_06_50_59.pth',
    'sonic/sonic_dynamics_step_97500_2025_09_18_11_25_59.pth',
]

for model_file in models:
    model_type = model_file.split('_')[1]
    target_dir = results_dir / f'{model_type}/checkpoints'
    path = hf_hub_download(repo_id=repo_id, filename=model_file, repo_type='model',
                           local_dir=str(target_dir), local_dir_use_symlinks=False)
    print(f'Downloaded: {path}')
"
```
- **ä¸‹è½½ä½ç½®**: `results/20260201_175440_sonic/`
  - `video/checkpoints/sonic/sonic_video_tokenizer_*.pth` (19.5 MB)
  - `latent/checkpoints/sonic/sonic_latent_actions_*.pth` (19.8 MB)
  - `dynamics/checkpoints/sonic/sonic_dynamics_*.pth` (16.2 MB)
- âœ… 3 ä¸ªæ¨¡å‹æ–‡ä»¶ä¸‹è½½æˆåŠŸ

### Step 4.5: æƒé‡åŠ è½½å…¼å®¹æ€§ä¿®å¤

**é—®é¢˜**: å®˜æ–¹æƒé‡ä¸ºå•ä¸ª `.pth` æ–‡ä»¶ï¼Œä½†ä»£ç æœŸæœ›ç›®å½•å¼ checkpointï¼ˆåŒ…å« `model_state_dict.pt` + `state.pt`ï¼‰

**ä¿®å¤**: ä¿®æ”¹ `utils/utils.py` ä¸­çš„ä¸‰ä¸ªåŠ è½½å‡½æ•°ï¼ˆ`load_videotokenizer_from_checkpoint`, `load_latent_actions_from_checkpoint`, `load_dynamics_from_checkpoint`ï¼‰ï¼Œæ·»åŠ æ¡ä»¶åˆ†æ”¯ï¼š

```python
# Handle both directory-based and single .pth file checkpoints
p = Path(checkpoint_path)
if p.is_file() and p.suffix == '.pth':
    # Single .pth file: load directly as state dict
    ckpt = torch.load(p, map_location='cpu', weights_only=False)
    model_sd = ckpt.get('model') or ckpt.get('model_state_dict') or ckpt
    state_cfg = {'config': {}} if not isinstance(ckpt, dict) or 'config' not in ckpt else {'config': ckpt.get('config', {})}
else:
    # Directory-based: load from subdirectories
    model_sd = torch.load(p / MODEL_CHECKPOINT, map_location='cpu', weights_only=True)
    state_cfg = torch.load(p / STATE, map_location='cpu', weights_only=False)
```

åŒæ—¶æ”¹è¿› `conditioning_dim` æ¨æ–­é€»è¾‘ä»¥æ”¯æŒå•æ–‡ä»¶æ¨¡å¼ã€‚

- âœ… å…¼å®¹æ€§ä¿®å¤å®Œæˆ

### Step 5: æ¨ç†é…ç½®è°ƒæ•´

ä¿®æ”¹ `configs/inference.yaml`ï¼š
```yaml
dataset: SONIC           # æ”¹ä» PONG åˆ° SONIC
device: cuda             # æ”¹ä» mps åˆ° cudaï¼ˆWindows å¿…éœ€ï¼‰
use_actions: true        # å¯ç”¨ action æ¨¡å‹
use_interactive_mode: false  # éäº¤äº’ï¼ˆè‡ªåŠ¨æ¨ç†ï¼‰
generation_steps: 10
context_window: 2
```

- âœ… é…ç½®ä¿®æ”¹å®Œæˆ

### Step 6: æ¨ç†æ‰§è¡Œ

#### 6.1 è‡ªåŠ¨æ¨ç†ï¼ˆéšæœº actionï¼‰
```powershell
$env:PYTHONPATH = "$pwd;$env:PYTHONPATH"
python scripts/run_inference.py --config configs/inference.yaml
```

**ç»“æœ**:
- âœ… æˆåŠŸåŠ è½½æ‰€æœ‰æ¨¡å‹å’Œæ•°æ®
- âœ… ç”Ÿæˆ 10 å¸§é¢„æµ‹
- MSE (GT vs Pred): 0.078128
- è¾“å‡ºæ–‡ä»¶:
  - `inference_results/inference_results_gt_vs_pred_20260201_175658.png` (312 KB)
  - `inference_results/inference_video_20260201_175658.mp4` (21 KB)

#### 6.2 äº¤äº’æ¨¡å¼æ¨ç†ï¼ˆç”¨æˆ·è¾“å…¥ actionï¼‰
```powershell
python scripts/run_inference.py --config configs/inference.yaml -- use_interactive_mode=true use_actions=false
```

**äº¤äº’æµç¨‹**:
```
Inferring frame 1/10
using interactive mode
Enter action id [0..15] for step 1: 5
Inferring frame 2/10
using interactive mode  
Enter action id [0..15] for step 2: 7
... (ç»§ç»­äº¤äº’)
```

- âœ… äº¤äº’æ¨¡å¼è¿è¡Œæ­£å¸¸
- å¯ä»¥ä¾æ¬¡è¾“å…¥ 0-15 çš„ action ç¼–å·æ§åˆ¶æ¨ç†è¿‡ç¨‹

---

## å…³é”®ä¿®æ”¹æ–‡ä»¶

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ |
|------|--------|
| `utils/utils.py` | æ”¯æŒå•æ–‡ä»¶ .pth checkpoint åŠ è½½ï¼ˆ3 ä¸ªå‡½æ•°ï¼‰ |
| `configs/inference.yaml` | device: cuda, dataset: SONIC, use_actions: true |
| `requirements-notorch.txt` | æ–°å»ºï¼Œç§»é™¤ torch ä¾èµ– |

---

## å¿«é€Ÿé‡å¯å‘½ä»¤

```powershell
# æ¿€æ´»ç¯å¢ƒ + è®¾ç½® PYTHONPATH + è‡ªåŠ¨æ¨ç†
.\.venv\Scripts\Activate.ps1
$env:PYTHONPATH = "$pwd;$env:PYTHONPATH"
python scripts/run_inference.py --config configs/inference.yaml

# æˆ–äº¤äº’æ¨¡å¼
python scripts/run_inference.py --config configs/inference.yaml -- use_interactive_mode=true use_actions=false
```

---

## è¾“å‡ºä½ç½®

æ‰€æœ‰æ¨ç†ç»“æœä¿å­˜åˆ° `inference_results/` ç›®å½•ï¼š
- **PNG**: çœŸå® vs ç”Ÿæˆå¸§å¯¹æ¯”å›¾
- **MP4**: å®Œæ•´è§†é¢‘åºåˆ—

---

## æ•…éšœæ’æŸ¥

| é—®é¢˜ | åŸå›  | è§£å†³ |
|------|------|------|
| CUDA unavailable | PyTorch è£…åˆ° CPU ç‰ˆæœ¬ | é‡è·‘ Step 2ï¼ŒéªŒè¯ `torch.cuda.is_available()` |
| æ‰¾ä¸åˆ°æ¨¡å‹ | ä¸‹è½½å¤±è´¥æˆ–è·¯å¾„é”™è¯¯ | æ£€æŸ¥ `results/20260201_175440_sonic/` ç¡®è®¤æ–‡ä»¶å­˜åœ¨ |
| æƒé‡åŠ è½½å¤±è´¥ | å•æ–‡ä»¶ vs ç›®å½•å¼æ ¼å¼ä¸åŒ¹é… | å·²é€šè¿‡ Step 4.5 ä¿®å¤ |
| äº¤äº’æ¨¡å¼è¾“å…¥è¶…èŒƒå›´ | è¾“å…¥ä¸åœ¨ 0-15 èŒƒå›´å†… | é‡æ–°è¾“å…¥æœ‰æ•ˆæ•°å­— (0-15) æˆ– 'q' é€€å‡º |

---

## æ€§èƒ½æŒ‡æ ‡

- **æ•°æ®åŠ è½½**: 41242 frames è€—æ—¶ ~2 ç§’
- **å•å¸§æ¨ç†é€Ÿåº¦**: å‡ ç™¾ msï¼ˆä¾èµ– GPU åˆ©ç”¨ç‡ï¼‰
- **æ˜¾å­˜å ç”¨**: ~3.4 GB / 8 GBï¼ˆRTX 3060 Tiï¼‰
- **ç”Ÿæˆè´¨é‡**: MSE â‰ˆ 0.078ï¼ˆä¸çœŸå®å¸§å¯¹æ¯”ï¼‰

---

## æ€»ç»“

âœ… **å®Œæ•´çš„ Windows + NVIDIA GPU æ¨ç†æµç¨‹å·²éªŒè¯é€šè¿‡**
- ç¯å¢ƒé…ç½®æ­£ç¡®
- æƒé‡å…¼å®¹æ€§å·²è§£å†³
- æ¨ç†ç»“æœå¯è§†åŒ–å·²ç”Ÿæˆ
- äº¤äº’æ¨¡å¼å¯æ­£å¸¸ä½¿ç”¨

ğŸ“Œ **ä¸‹ä¸€æ­¥**å¯ä»¥å°è¯•ï¼š
1. æ”¹å˜è¶…å‚æ•° (generation_steps, temperature ç­‰)
2. åˆ‡æ¢ä¸åŒæ•°æ®é›† (éœ€å…ˆä¸‹è½½)
3. è®­ç»ƒè‡ªå·±çš„æ¨¡å‹ (è§ scripts/train_*.py)
