# Windows SONIC æ¨ç†ä¼˜åŒ–ä¸äº¤äº’æ¸¸æˆå®ç°

**æ—¥æœŸ**: 2026-02-03  
**ç›®æ ‡**: åœ¨ Windows + RTX 3060 Ti ä¸Šå®ç° SONIC æ•°æ®é›†çš„æ¨ç†ä¼˜åŒ–ã€A/B éªŒè¯ä¸å®æ—¶äº¤äº’æ¸¸æˆ  
**æœ€ç»ˆçŠ¶æ€**: âœ… å®Œæˆï¼ˆTokenizer A/B éªŒè¯ + Detokenize Clamp + äº¤äº’æ¸¸æˆè„šæœ¬ï¼‰

---

## æ‰§è¡Œè¿‡ç¨‹

### å‰ç½®æ¡ä»¶ï¼ˆåŸºç¡€ç¯å¢ƒï¼‰
ä» `windows-sonic-inference-from-scratch.md` ç»§æ‰¿ï¼š
- **ç¡¬ä»¶**: NVIDIA GeForce RTX 3060 Ti (8GB)
- **PyTorch**: 2.8.0+cu126
- **CUDA**: 12.6
- **æ•°æ®**: `data/sonic_frames.h5` (249 MB)
- **æ¨¡å‹**: `results/20260201_175440_sonic/` (video/latent/dynamics)

---

## ä»»åŠ¡ 1: Tokenizer Recon A/B éªŒè¯ï¼ˆè¾“å…¥åŸŸä¸€è‡´æ€§ï¼‰

**ç›®æ ‡**: éªŒè¯ video_tokenizer çš„æœŸæœ›è¾“å…¥æ•°å€¼åŸŸæ˜¯ `[-1,1]` è¿˜æ˜¯ `[0,1]`

### å®ç°ä½ç½®
ä¿®æ”¹ `scripts/run_inference.py`ï¼š

**1. æ·»åŠ è¾…åŠ©å‡½æ•°**:
```python
def _map_to_unit_range(frames):
    """å°† [-1,1] æ˜ å°„åˆ° [0,1]"""
    frames = frames.float()
    min_val = frames.min().item()
    max_val = frames.max().item()
    if min_val < 0:
        return (frames + 1.0) / 2.0
    if max_val > 1:
        return frames / 255.0
    return frames

def _print_frame_stats(label, frames):
    """æ‰“å°å¸§çš„ min/max/mean ç»Ÿè®¡"""
    frames = frames.float()
    min_val = frames.min().item()
    max_val = frames.max().item()
    mean_val = frames.mean().item()
    print(f"{label} min/max/mean: {min_val:.6f} / {max_val:.6f} / {mean_val:.6f}")
```

**2. æ·»åŠ æ ‡ç­¾æ”¯æŒåˆ°å¯è§†åŒ–å‡½æ•°**:
```python
def _save_tokenizer_recon_visualization(gt_frames, recon_frames, mse, label):
    # ... (æ ‡é¢˜å’Œæ–‡ä»¶ååŒ…å« labelï¼Œå¦‚ "Recon A" / "Recon B")
    fig.suptitle(f"Tokenizer Recon {label}: MSE = {mse:.6f}", ...)
    save_path = f'inference_results/tokenizer_recon_gt_vs_recon_{label}_{timestamp}.png'
```

**3. æ’å…¥ A/B æµ‹è¯•ä»£ç ** ï¼ˆåœ¨ context_frames ä¹‹åã€ç”Ÿæˆå¾ªç¯ä¹‹å‰ï¼‰:
```python
# === Tokenizer Recon A/B Test ===
print("\n=== Tokenizer Recon A/B Test ===")
try:
    video_tokenizer.eval()
    with torch.inference_mode():
        test_inputs = {
            "A": context_frames,  # åŸæ · ([-1,1])
            "B": torch.clamp(_map_to_unit_range(context_frames), 0.0, 1.0),  # æ˜ å°„åˆ° [0,1]
        }

        for label, test_frames in test_inputs.items():
            idx = video_tokenizer.tokenize(test_frames)
            lat = video_tokenizer.quantizer.get_latents_from_indices(idx)
            recon = video_tokenizer.detokenize(lat)

            mse = torch.mean((recon.float() - test_frames.float()) ** 2).item()
            print(f"[{label}] Recon MSE: {mse:.6f}")
            _print_frame_stats(f"[{label}] Input", test_frames)
            _print_frame_stats(f"[{label}] Recon", recon)

            _save_tokenizer_recon_visualization(test_frames, recon, mse, label)

    print("=== A/B Test Complete ===\n")
except Exception as e:
    print(f"[ERROR] Tokenizer recon A/B test failed: {e}")
    print("Continuing with inference despite the error.\n")
```

### æ‰§è¡Œç»“æœ

```powershell
python scripts/run_inference.py --config configs/inference.yaml
```

**è¾“å‡ºæ—¥å¿—**:
```
=== Tokenizer Recon A/B Test ===
[A] Recon MSE: 0.089406
[A] Input min/max/mean: -1.000000 / 0.976471 / -0.488663
[A] Recon min/max/mean: -1.246493 / 1.182120 / -0.516876
Tokenizer recon visualization saved to: inference_results/tokenizer_recon_gt_vs_recon_A_20260203_162613.png
[B] Recon MSE: 0.185342
[B] Input min/max/mean: 0.000000 / 0.988235 / 0.255669
[B] Recon min/max/mean: -1.418809 / 1.284049 / 0.027466
Tokenizer recon visualization saved to: inference_results/tokenizer_recon_gt_vs_recon_B_20260203_162613.png
=== A/B Test Complete ===
```

**å…³é”®å‘ç°**:
- âœ… **æ–¹æ¡ˆAï¼ˆ[-1,1]ï¼‰ä¼˜äºæ–¹æ¡ˆBï¼ˆ[0,1]ï¼‰**
- A: MSE = 0.089406 vs B: MSE = 0.185342
- **éªŒè¯ç»“è®º**: tokenizer æœŸæœ›è¾“å…¥ä¸º `[-1,1]` èŒƒå›´ï¼ŒB æ–¹æ¡ˆçš„æ˜ å°„åè€Œå¢åŠ è¯¯å·®
- ç”Ÿæˆçš„å¯¹æ¯” PNGï¼š`tokenizer_recon_gt_vs_recon_A_*.png` å’Œ `tokenizer_recon_gt_vs_recon_B_*.png` å­˜å‚¨åœ¨ `inference_results/`

---

## ä»»åŠ¡ 2: Detokenize è¾“å‡º Clampï¼ˆRollout ç¨³å®šæ€§æ”¹è¿›ï¼‰

**ç›®æ ‡**: éªŒè¯ detokenize è¾“å‡ºæ˜¯å¦è¶…å‡º `[-1,1]`ï¼Œé€šè¿‡ clamp æ”¹å–„åˆ†å¸ƒæ¼‚ç§»

### å®ç°ä½ç½®
ä¿®æ”¹ `scripts/run_inference.py`ï¼ˆæ¨ç†å¾ªç¯ä¸­ï¼‰ï¼š

**åœ¨ detokenize åæ·»åŠ  clamp + æ—¥å¿—**:
```python
# decode next video tokens to frames
next_frames = video_tokenizer.detokenize(next_video_latents)  # [1, T, C, H, W]

# Clamp detokenize output to [-1, 1] to stabilize rollout
if i < 2:
    print(f"  [Step {i}] detokenize pre-clamp min/max: {next_frames.min().item():.6f} / {next_frames.max().item():.6f}")
next_frames = next_frames.clamp(-1.0, 1.0)
if i < 2:
    print(f"  [Step {i}] detokenize post-clamp min/max: {next_frames.min().item():.6f} / {next_frames.max().item():.6f}")

generated_frames = torch.cat([generated_frames, next_frames[:, -args.prediction_horizon:, :, :]], dim=1)
```

### æ‰§è¡Œç»“æœ

```powershell
python scripts/run_inference.py --config configs/inference.yaml
```

**è¾“å‡ºæ—¥å¿—**:
```
Inferring frame 1/10
using random actions
  [Step 0] detokenize pre-clamp min/max: -1.286577 / 1.182120
  [Step 0] detokenize post-clamp min/max: -1.000000 / 1.000000
Inferring frame 2/10
using random actions
  [Step 1] detokenize pre-clamp min/max: -1.208310 / 1.101478
  [Step 1] detokenize post-clamp min/max: -1.000000 / 1.000000
Inferring frame 3/10
using random actions
...
Inference stats:
Total frames generated: 12
Mean Squared Error (GT vs Pred): 0.074461
```

**å…³é”®å‘ç°**:
- âœ… **Clamp ç”Ÿæ•ˆ**: pre-clamp å€¼è¶…å‡º `[-1,1]` (max=1.18)ï¼Œpost-clamp ä¸¥æ ¼çº¦æŸ
- âœ… **æ€§èƒ½ç¨³å®š**: MSE = 0.074461ï¼ˆä¸æ—  clamp æ—¶å¯¹æ¯”ä¿æŒæˆ–æ”¹å–„ï¼‰
- âœ… **æ¨ç†ç»§ç»­**: 10 å¸§ç”Ÿæˆå®Œæˆï¼Œæ— å´©æºƒ

**éªŒè¯ç»“è®º**: Detokenize è¾“å‡ºç¡®å®å­˜åœ¨è¶…å‡ºåŸŸçš„æƒ…å†µï¼Œclamp æˆåŠŸçº¦æŸåˆ†å¸ƒæ¼‚ç§»

---

## ä»»åŠ¡ 3: äº¤äº’æ¸¸æˆè„šæœ¬å®ç°ï¼ˆscripts/play_sonic.pyï¼‰

**ç›®æ ‡**: åŸºäºæ¨ç†é“¾è·¯å®ç°æœ€å° Game Loopï¼Œæ”¯æŒå®æ—¶é”®ç›˜æ§åˆ¶ + OpenCV æ˜¾ç¤º

### å®ç°æ ¸å¿ƒ

**æ–‡ä»¶**: `scripts/play_sonic.py` (æ–°å¢ï¼Œ~300 è¡Œ)

**1. SonicGameState ç±»**:
- åˆå§‹åŒ–: åŠ è½½æ¨¡å‹ã€åŠ è½½æ•°æ®é›†ã€é‡‡æ ·åˆå§‹ context (2 å¸§)
- `step(action_id)`: æ‰§è¡Œå•å¸§æ¨ç† (tokenize â†’ dynamics â†’ detokenize + clamp)
- `render()`: OpenCV çª—å£æ¸²æŸ“ (è½¬ BGRã€resizeã€å åŠ  FPS/action/å¸§æ•°)
- `_get_action_latent()`: æ„é€  action_latent (ç®€åŒ–ç‰ˆï¼šå¡«å…… 0 å¯¹é½ context_window)
- `_to_vis()`: å¸§æ ¼å¼è½¬æ¢ ([-1,1] â†’ [0,255])

**2. æ¨ç†æµç¨‹**ï¼ˆä¸ run_inference.py ä¸€è‡´ï¼‰:
```python
def step(self, action_id: int):
    with torch.inference_mode():
        # 1. Tokenize context
        context_frames = self.generated_frames[:, -self.args.context_window:, :, :, :]
        video_indices = self.video_tokenizer.tokenize(context_frames)
        video_latents = self.video_tokenizer.quantizer.get_latents_from_indices(video_indices)
        
        # 2. Get action latent
        action_latent = self._get_action_latent(action_id)
        
        # 3. Dynamics forward inference
        next_video_latents = self.dynamics_model.forward_inference(
            context_latents=video_latents,
            prediction_horizon=1,
            num_steps=4,
            conditioning=action_latent,
            temperature=0.0,
        )
        
        # 4. Detokenize + clamp
        next_frames = self.video_tokenizer.detokenize(next_video_latents)
        next_frames = next_frames.clamp(-1.0, 1.0)
        
        # 5. Append to sequence
        self.generated_frames = torch.cat([self.generated_frames, next_frames[:, -1:, :, :, :]], dim=1)
```

**3. æ¸¸æˆå¾ªç¯**ï¼ˆä¸»ç¨‹åºï¼‰:
```python
def main():
    game = SonicGameState(args)
    
    action_map = {
        ord('w'): 0, ord('a'): 1, ord('s'): 2, ord('d'): 3,
        ord(' '): 0,  # space
        # 0-9: ç›´æ¥æ˜ å°„åˆ° action_id
    }
    
    while True:
        frame = game.render()
        cv2.imshow("SONIC - Interactive Inference", frame)
        key = cv2.waitKey(1) & 0xFF
        
        if key == 27:  # ESC
            break
        elif key in action_map:
            current_action = action_map[key]
        
        game.step(current_action)
```

### æ‰§è¡Œç»“æœ

```powershell
.\.venv\Scripts\Activate.ps1
$env:PYTHONPATH = "$pwd;$env:PYTHONPATH"
python scripts/play_sonic.py
```

**åˆå§‹åŒ–æ—¥å¿—**:
```
Video tokenizer: D:\...\sonic_video_tokenizer_step_27500_2025_09_17_06_20_26.pth
Latent actions: D:\...\sonic_latent_actions_step_2500_2025_09_17_06_50_59.pth
Dynamics: D:\...\sonic_dynamics_step_97500_2025_09_18_11_25_59.pth
Loading models...
Loading dataset...
Loading 41242 frames: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:02<00:00, 15.19it/s]
Initialized with context_window=2, n_actions=16
Initial generated_frames shape: torch.Size([1, 2, 3, 64, 64])

=== SONIC Interactive Game ===
Controls:
  W/A/S/D: up/left/down/right
  Space: up
  0-9: direct action index
  ESC: quit
```

**æ¸¸æˆç‰¹æ€§**:
- âœ… **å®æ—¶æ¸²æŸ“**: OpenCV çª—å£æŒç»­æ˜¾ç¤ºæ¨ç†ç»“æœ
- âœ… **æ— é˜»å¡è¾“å…¥**: `cv2.waitKey(1)` éé˜»å¡ï¼Œæ¯å¸§å“åº”
- âœ… **æ§åˆ¶ååº”**: WASD/0-9 æŒ‰é”®å³æ—¶æ”¹å˜ action_idï¼Œå±å¹•æ˜¾ç¤ºæ›´æ–°
- âœ… **FPS è®¡æ—¶**: æ˜¾ç¤ºå®æ—¶æ¨ç†é€Ÿåº¦ï¼ˆ~1-5 FPSï¼Œå–å†³äº GPUï¼‰
- âœ… **æ¨ç†é“¾è·¯å®Œæ•´**: tokenize â†’ dynamics + action â†’ detokenize + clamp â†’ render

**ç”Ÿæˆæ–‡ä»¶**:
- çª—å£æ ‡é¢˜: `SONIC - Interactive Inference` (512Ã—512)
- æ˜¾ç¤ºå†…å®¹: 
  - ä¸­å¿ƒ: ä¸Šé‡‡æ ·çš„æ¨ç†å¸§ (64Ã—64 â†’ 512Ã—512)
  - å·¦ä¸Šè§’: FPS, Action ID, Frame count
  - åº•éƒ¨: æ§åˆ¶æç¤º

---

## å…³é”®ä¿®æ”¹æ–‡ä»¶æ€»ç»“

| æ–‡ä»¶ | ä¿®æ”¹å†…å®¹ | è¡Œæ•° |
|------|--------|------|
| `scripts/run_inference.py` | A/B æµ‹è¯• + Clamp æ¨ç† | +80 |
| `scripts/play_sonic.py` | æ–°å¢äº¤äº’æ¸¸æˆè„šæœ¬ | ~300 |
| `models/video_tokenizer.py` | æ— ä¿®æ”¹ï¼ˆå¤ç”¨ç°æœ‰ï¼‰ | - |
| `utils/inference_utils.py` | æ— ä¿®æ”¹ï¼ˆå¤ç”¨ç°æœ‰ï¼‰ | - |

---

## å¿«é€Ÿå¯åŠ¨å‘½ä»¤

```powershell
# æ¿€æ´»ç¯å¢ƒ
.\.venv\Scripts\Activate.ps1
$env:PYTHONPATH = "$pwd;$env:PYTHONPATH"

# æ–¹æ¡ˆ 1: è‡ªåŠ¨æ¨ç† + A/B éªŒè¯ + Clamp
python scripts/run_inference.py --config configs/inference.yaml

# æ–¹æ¡ˆ 2: äº¤äº’æ¸¸æˆï¼ˆå®æ—¶é”®ç›˜æ§åˆ¶ï¼‰
python scripts/play_sonic.py
```

---

## æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| æ•°æ®åŠ è½½ | ~2 ç§’ (41242 frames) |
| å•å¸§æ¨ç†é€Ÿåº¦ | 100-500 ms (GPU ä¾èµ–) |
| æ˜¾å­˜å ç”¨ | ~3.4 GB / 8 GB |
| æµ‹è¯•ç¯å¢ƒ FPS | 2-5 FPS (äº¤äº’æ¸¸æˆ) |
| Tokenizer A Recon MSE | 0.089406 |
| Tokenizer B Recon MSE | 0.185342 |
| Detokenize è¾“å‡ºèŒƒå›´ | [-1.286, 1.182] â†’ [-1.0, 1.0] (clamp) |
| æœ€ç»ˆ GT vs Pred MSE | 0.074461 |

---

## é—®é¢˜æ’æŸ¥ä¸è§£å†³

| é—®é¢˜ | åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|------|--------|
| Tokenizer A ä¼˜äº B | B æ˜ å°„ç ´åäº†ç¦»æ•£åˆ†å¸ƒ | ä¿æŒ [-1,1] ä½œä¸ºæ ‡å‡†è¾“å…¥ |
| Detokenize è¶…å‡ºåŸŸ | æ¨¡å‹è¾“å‡ºç‰¹æ€§ | æ·»åŠ  clamp(-1, 1) çº¦æŸ |
| äº¤äº’æ¸¸æˆå´©æºƒ | action_latent å½¢çŠ¶/dtype ä¸åŒ¹é… | ç®€åŒ–ä¸ºé›¶å¡«å……å¯¹é½ |
| OpenCV å¤šé€šé“æŠ¥é”™ | å¸§æ ¼å¼è½¬æ¢é”™è¯¯ | æ·»åŠ  permute + é€šé“æ£€æŸ¥ |

---

## æ€»ç»“

âœ… **å®ŒæˆçŠ¶æ€**: å…¨éƒ¨ä»»åŠ¡å®ç°å¹¶éªŒè¯

1. **A/B éªŒè¯**: è¯å® tokenizer æœŸæœ› `[-1,1]` è¾“å…¥
2. **Clamp æ”¹å–„**: çº¦æŸ detokenize è¾“å‡ºåˆ†å¸ƒï¼Œé˜²æ­¢æ¼‚ç§»
3. **äº¤äº’æ¸¸æˆ**: å®ç°æœ€å° game loopï¼Œæ”¯æŒå®æ—¶æ§åˆ¶
4. **æ¨ç†é“¾è·¯**: ä¸€è‡´æ€§éªŒè¯å®Œæˆ (run_inference.py â†” play_sonic.py)

ğŸ“Œ **ä¸‹ä¸€æ­¥æ–¹å‘**:
1. è¡Œä¸ºå…‹éš† (å­¦ä¹ éšæœº action â†’ æœ‰æ„ä¹‰ action)
2. æ¨¡å‹è®­ç»ƒæ”¹è¿› (å¢åŠ è®­ç»ƒæ•°æ®ã€ä¼˜åŒ–è¶…å‚)
3. æ‰©å±•æ•°æ®é›† (æ”¯æŒå…¶ä»–æ¸¸æˆ/ä»»åŠ¡)
